{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPNDS/98G/e+b7jUhjigevF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Patrick-Setubal/data_science_analytics/blob/main/alura_curso/formacao_data_science/CorretorOrtograficoNLP/CorretorOrtograficoNLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criando Um Corretor Ortografico NLP"
      ],
      "metadata": {
        "id": "6hIcg6m5hKZu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importações"
      ],
      "metadata": {
        "id": "P8kVPGUEdWBi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "M0H2LSW0eI8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b411b177-aaa4-46ff-adb2-8ef5ce6462a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# Importações\n",
        "import requests\n",
        "import nltk \n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Coletar e Limpar Dados"
      ],
      "metadata": {
        "id": "F3G3PAgSdip7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar Função que separa as palavras dos tokens\n",
        "def _separar_palavras(list_tokens):\n",
        "  lista_palavras = []\n",
        "  for token in list_tokens:\n",
        "    if token.isalpha():\n",
        "      lista_palavras.append(token)\n",
        "  return lista_palavras\n",
        "\n",
        "# Criar função para normalçizar a lista de palavras (tudo Minusculo)\n",
        "def _normalizacao(lista_palavras):\n",
        "  lista_normalizada = []\n",
        "  for palavra in lista_palavras:\n",
        "    lista_normalizada.append(palavra.lower())\n",
        "  return lista_normalizada\n",
        "\n",
        "# Função Principal para fazer a leitura dos dados\n",
        "def ler_dados(link):\n",
        "  dados = requests.get(link).text\n",
        "\n",
        "  # Criando uma lista de tokens (ex:  \"Hoje?\" = ['Hoje', '?'] )\n",
        "  list_tokens = nltk.tokenize.word_tokenize(dados)\n",
        "\n",
        "  # Usando Funções\n",
        "  lista_palavras = _separar_palavras(list_tokens)\n",
        "  lista_normalizada = _normalizacao(lista_palavras)\n",
        "  print(f\"Possui {len(lista_normalizada)} palavras\")\n",
        "  return lista_normalizada\n",
        "\n",
        "\n",
        "link = \"https://raw.githubusercontent.com/Patrick-Setubal/data_science_analytics/main/alura_curso/formacao_data_science/CorretorOrtograficoNLP/artigos.txt\"\n",
        "lista_normalizada = ler_dados(link)\n"
      ],
      "metadata": {
        "id": "4vxbWRF38zwE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ed321ef-01cf-4dc7-996d-f6f011101128"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Possui 403104 palavras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Funções Do corretor"
      ],
      "metadata": {
        "id": "USa6Wby3gpsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Variavel Global com todas as letras\n",
        "letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
        "\n",
        "# Insere letra entre as fatias\n",
        "def _insere_letras(fatias):\n",
        "  novas_palavras = []\n",
        "  for E, D in fatias:\n",
        "    for letra in letras:\n",
        "      novas_palavras.append(E + letra + D)\n",
        "  return novas_palavras\n",
        "\n",
        "# Troca letra entre as fatias\n",
        "def _troca_letras(fatias):\n",
        "  novas_palavras = []\n",
        "  for E, D in fatias:\n",
        "    for letra in letras:\n",
        "      novas_palavras.append(E + letra + D[1:])\n",
        "  return novas_palavras\n",
        "\n",
        "# Deleta letra entre as fatias\n",
        "def _deletando_caracteres(fatias):\n",
        "  novas_palavras = []\n",
        "  for E, D in fatias:\n",
        "    novas_palavras.append(E + D[1:])\n",
        "  return novas_palavras\n",
        "\n",
        "\n",
        "# Troca letra entre as fatias\n",
        "def _inverte_letra(fatias):\n",
        "  novas_palavras = []\n",
        "  for E, D in fatias:\n",
        "    if len(D)>1:\n",
        "      novas_palavras.append(E + D[1] + D[0] + D[2:])\n",
        "  return novas_palavras\n",
        "\n",
        "\n",
        "# Gerar palavras \n",
        "def gerador_palavra(palavra):\n",
        "  fatias = []\n",
        "  for i in range(len(palavra)+1):\n",
        "    fatias.append((palavra[:i],palavra[i:]))\n",
        "    palavras_geradas = _insere_letras(fatias)\n",
        "    palavras_geradas += _deletando_caracteres(fatias)\n",
        "    palavras_geradas += _troca_letras(fatias)\n",
        "    palavras_geradas += _inverte_letra(fatias)\n",
        "\n",
        "  return palavras_geradas\n",
        "\n",
        "# Define a probabilidade da palavra estar certa com base no dataset\n",
        "# Variavel Global Utilizando a lista_normalizada\n",
        "frequencia = nltk.FreqDist(lista_normalizada)\n",
        "total_palavras = len(lista_normalizada)\n",
        "def _probabilidade(palavra_gerada):\n",
        "  return frequencia[palavra_gerada]/total_palavras\n",
        "\n",
        "# Função principal Corrige a palavra\n",
        "def corretor(palavra):\n",
        "  palavras_geradas = gerador_palavra(palavra)\n",
        "  palavra_correta = max(palavras_geradas, key=_probabilidade)\n",
        "  return palavra_correta"
      ],
      "metadata": {
        "id": "zKG3Qc9XA88l"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Funções do Avaliador"
      ],
      "metadata": {
        "id": "bYewnEy0hcu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# coleta e trata os dados para teste\n",
        "def cria_dados_teste(link_arquivo):\n",
        "  lista_palavras_teste = []\n",
        "  f = requests.get(link_arquivo).text.split('\\n')\n",
        "  for linha in f:\n",
        "    if ' ' in linha:\n",
        "      correta, errada = linha.split(' ')\n",
        "      lista_palavras_teste.append((correta, errada))\n",
        "  return lista_palavras_teste\n",
        "\n",
        "\n",
        "# Função avaliador printa a porcentagem de acertos \n",
        "def avaliador(testes, vocabulario):\n",
        "  numero_palavras = len(testes)\n",
        "  acertou = 0\n",
        "  desconhecida = 0\n",
        "  for correta, errada in testes:\n",
        "    desconhecida += (correta not in vocabulario)\n",
        "    if correta == corretor(errada):\n",
        "      acertou += 1\n",
        "        \n",
        "\n",
        "\n",
        "  taxa_desconhecida =  round(desconhecida*100/numero_palavras, 2)\n",
        "  taxa_acerto = round(acertou*100/numero_palavras, 2)\n",
        "  print(f'acertou {acertou} de {numero_palavras}')\n",
        "  print(f'taxas acerto e de {taxa_acerto}%')\n",
        "  print(f'taxas de palavra desconhecida de {taxa_desconhecida}%')\n",
        "\n",
        "\n",
        "# Criar Dados Para Teste\n",
        "link = 'https://raw.githubusercontent.com/Patrick-Setubal/data_science_analytics/main/alura_curso/formacao_data_science/CorretorOrtograficoNLP/palavras.txt'\n",
        "lista_teste = cria_dados_teste(link)\n",
        "\n",
        "avaliador(lista_teste,set(lista_normalizada))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p44-N2ssG82i",
        "outputId": "2bc42a20-7360-4e1a-9962-9998d56a5ea5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acertou 142 de 186\n",
            "taxas acerto e de 76.34%\n",
            "taxas de palavra desconhecida de 6.99%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Uso do Corretor\n"
      ],
      "metadata": {
        "id": "8UEq2ZzRiMoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lista de palavras a serem corregidas \n",
        "Uso_Corretor = ['logica', 'lgica', 'lógca', 'lógiac']\n",
        "Uso_Corretor2 = ['achine', 'amchine','machiine','macoine',]\n",
        "Uso_Corretor3 = ['learing', 'laerning','kearning','leearning',]\n",
        "\n",
        "for palavra in Uso_Corretor:\n",
        "  print(f'{palavra} = {corretor(palavra)}')\n",
        "\n",
        "print('-------')\n",
        "\n",
        "for palavra in Uso_Corretor2:\n",
        "  print(f'{palavra} = {corretor(palavra)}')\n",
        "\n",
        "print('-------')\n",
        "\n",
        "for palavra in Uso_Corretor3:\n",
        "  print(f'{palavra} = {corretor(palavra)}')"
      ],
      "metadata": {
        "id": "fTiTz61iNx9J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df7f82b6-5319-49ee-eef5-8ae15dc9f08f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logica = lógica\n",
            "lgica = lógica\n",
            "lógca = lógica\n",
            "lógiac = lógica\n",
            "-------\n",
            "achine = machine\n",
            "amchine = machine\n",
            "machiine = machine\n",
            "macoine = machine\n",
            "-------\n",
            "learing = learning\n",
            "laerning = learning\n",
            "kearning = learning\n",
            "leearning = learning\n"
          ]
        }
      ]
    }
  ]
}